@misc{kuhnRecipesPreprocessingFeature2024,
  title = {Recipes: {{Preprocessing}} and {{Feature Engineering Steps}} for {{Modeling}}},
  shorttitle = {Recipes},
  author = {Kuhn, Max and Wickham, Hadley and Hvitfeldt, Emil and Software, Posit and PBC},
  year = {2024},
  month = jul,
  urldate = {2024-07-09},
  abstract = {A recipe prepares your data for modeling. We provide an extensible framework for pipeable sequences of feature engineering steps provides preprocessing tools to be applied to data. Statistical parameters for the steps can be estimated from an initial data set and then applied to other data sets. The resulting processed output can then be used as inputs for statistical or machine learning models.},
  copyright = {MIT + file LICENSE}
}

@inproceedings{mckinney-proc-scipy-2010,
  title = {Data {{Structures}} for {{Statistical Computing}} in {{Python}}},
  booktitle = {Proceedings of the 9th {{Python}} in {{Science Conference}}},
  author = {McKinney, Wes},
  editor = {{van der Walt}, St{\'e}fan and Millman, Jarrod},
  year = {2010},
  pages = {56--61},
  doi = {10.25080/Majora-92bf1922-00a}
}

@misc{mozzilloEvaluationDataframeLibraries2024,
  title = {Evaluation of {{Dataframe Libraries}} for {{Data Preparation}} on a {{Single Machine}}},
  author = {Mozzillo, Angelo and Zecchini, Luca and Gagliardelli, Luca and Aslam, Adeel and Bergamaschi, Sonia and Simonini, Giovanni},
  year = {2024},
  month = jun,
  number = {arXiv:2312.11122},
  eprint = {2312.11122},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-07-09},
  abstract = {Data preparation is a trial-and-error process that typically involves countless iterations over the data to define the best pipeline of operators for a given task. With tabular data, practitioners often perform that burdensome activity on local machines by writing ad hoc scripts with libraries based on the Pandas dataframe API and testing them on samples of the entire dataset---the faster the library, the less idle time its users have.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
  file = {C:\Users\Robin\Zotero\storage\B2KUGHJ3\Mozzillo et al. - 2024 - Evaluation of Dataframe Libraries for Data Prepara.pdf}
}

@inproceedings{paszkePyTorchImperativeStyle2019,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  year = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  urldate = {2023-04-18},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.},
  file = {C:\Users\Robin\Zotero\storage\DBZHEP84\Paszke et al_2019_PyTorch.pdf}
}

@article{pedregosa_scikit-learn_2011,
  title = {Scikit-Learn: {{Machine}} Learning in Python},
  shorttitle = {Scikit-Learn},
  author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  number = {85},
  pages = {2825--2830},
  issn = {1533-7928},
  urldate = {2022-12-21},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.}
}

@misc{PolarsPolars2024,
  title = {Pola-Rs/Polars},
  year = {2024},
  month = jul,
  urldate = {2024-07-09},
  abstract = {Dataframes powered by a multithreaded, vectorized query engine, written in Rust},
  howpublished = {Polars},
  keywords = {arrow,dataframe,dataframe-library,dataframes,out-of-core,polars,python,rust}
}

@inproceedings{waterAnotherICUBenchmark2023,
  title = {Yet {{Another ICU Benchmark}}: {{A Flexible Multi-Center Framework}} for {{Clinical ML}}},
  shorttitle = {Yet {{Another ICU Benchmark}}},
  booktitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  author = {van de Water, Robin and Schmidt, Hendrik Nils Aurel and Elbers, Paul and Thoral, Patrick and Arnrich, Bert and Rockenschaub, Patrick},
  year = {2023},
  month = oct,
  urldate = {2024-04-12},
  abstract = {Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. Given the abundance of available data from electronic health records, the intensive care unit (ICU) is a natural habitat for ML. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transparent preprocessing pipeline and extensible training code for multiple ML and deep learning models, YAIB enables unified model development, transfer, and evaluation. Our benchmark comes with five predefined established prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and length of stay) developed in collaboration with clinicians. Adding further tasks is straightforward by design. Using YAIB, we demonstrate that the choice of dataset, cohort definition, and preprocessing have a major impact on the prediction performance --- often more so than model class --- indicating an urgent need for YAIB as a holistic benchmarking tool. We provide our work to the clinical ML community to accelerate method development and enable real-world clinical implementations.},
  langid = {english},
  file = {C:\Users\Robin\Zotero\storage\BKYUEA8A\Water et al_2023_Yet Another ICU Benchmark.pdf}
}
